{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification and regression\n",
    "- distance, k, ties, missing values\n",
    "- optimality and assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making kNN fast:\n",
    "    - kd-trees\n",
    "    - Inverted list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d(x_i, x) = \\exp\\left(-\\frac{(x_i - x)^2}{2\\sigma^2}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Small Value : Unstable decision boundary\n",
    "- Large Value : Everything classified decision boundary\n",
    "- Affects smoothness of decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting k is a hyperparameter. We can use cross-validation to select the best k.\n",
    "- Create validation set from training set\n",
    "- vary k, train model, validation error\n",
    "- Pick k which gives the best performance on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numeric attributes: Euclidean distance\n",
    "- Categorical attributes: Hamming distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eucledian distance\n",
    "    - $d(x, x`) = \\sqrt{\\sum_{i=1}^d (xd - x`d)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hamming distance\n",
    "    - $d(x, x`) = \\sum_{i=1}^d 1(xd \\neq x`d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Minkowski distance\n",
    "    - $d(x, x`) = \\left(\\sum_{i=1}^d |xd - x`d|^p\\right)^{1/p}$\n",
    "\n",
    "- Mahalanobis distance\n",
    "    - $d(x, x`) = \\sqrt{(x - x`)^\\top S^{-1} (x - x`) }$\n",
    "\n",
    "- Kullback-Leibler divergence\n",
    "    - $d(x, x`) = \\sum_{i=1}^d x_i \\log\\left(\\frac{x_i}{x`_i}\\right)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
